## 机器学习9 集成学习

### 9.1 个体与集成

**集成学习(ensemble learning)**通过构建并结合多个学习期来完成学习任务，有时也被称为**多分类器系统(multi-classifier system)**、**基于委员会的学习(committee-based learning)**等。

集成学习的思路如下：首先产生一组**个体学习器(indicidual learner)**，再用某种策略将它们结合起来。个体学习器(基学习器)通常由一个现有的学习算法(基学习算法)从训练数据中产生，例如决策树、BP神经网络等，此时集成中只包含同种类型的个体学习器，例如“决策树集成”中全是决策树，这样的集成是**同质的(homogeneous)**，同质集成中的个体学习器亦称为**基学习器(base learner)**。集成也可以包含不同类型的个体学习器，此时称其为**异质的(heterogenous)**，相应的个体学习器一般不称基学习器，而是称为**组件学习器(component learner)**。

<img src="images/image-20200429101621224.png" style="zoom:50%;" />

<img src="images/image-20200429101621224.png" style="zoom:50%;" />

历史上，Kearns和Valiant首先提出了**强可学习(strongly learnable)**和**弱可学习(weakly learnable)**的概念。他们指出：在**概率近似正确(probably approximately correct, PAC)**学习的框架中，一个概念(一个类)，如果存在一个多项式的学习算法能够学习它，并且正确率很高，就称这个概念是强可学习的；一个概念，如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，就称这个概念是弱可学习的。后来Schapire证明强可学习和弱可学习是等价的，也就是说，**在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的**。集成学习便是研究如何将弱学习算法提升为强学习算法的理论。

集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。这对**弱学习器**尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器。但需注意的是，虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实践中，**往往会使用比较强的学习器进行集成**。

在经验中，如果把好坏不等的东西掺到一起，那么通常结果会是比最坏的要好一些，比最好的要坏一些。集成学习要获得比最好的单一学习器更好的性能，个体学习器应“**好而不同**”，即**个体学习器要同时具备准确性和多样性**。

根据个体学习器的生成方式，目前集成学习方法大致可分为两大类，即个体学习器之间存在强依赖关系、必须串行生成的**序列化方法**，以及个体学习器间不存在强依赖关系，可同时生成的**并行化方法**。前者的代表是**Boosting**，后者的代表是**Bagging和随机森林**。

### 9.2 集成学习的误差分析

给定一个学习任务，假设输入$x$与输出$y$的真实关系为$y=h(x)$。对于$M$个不同的模型$f_1(x),\cdots,f_M(x)$，每个模型的**期望错误**为：
$$
\begin{aligned}
\mathcal{R}(f_{m}) &=\mathbb{E}_{{x}}[(f_{m}({x})-h({x}))^{2}] \\
&=\mathbb{E}_{{x}}[\epsilon_{m}({x})^{2}]
\end{aligned}
$$
其中$\epsilon_{m}(\boldsymbol{x})=f_{m}({x})-h({x})$为模型$m$在样本$x$上的错误。那么所有模型的平均错误为：
$$
\bar{\mathcal{R}}(f)=\frac{1}{M} \sum_{m=1}^{M} \mathbb{E}_{\boldsymbol{x}}[\epsilon_{m}({x})^{2}]
$$
使用**投票法**进行模型结合时，最终模型的输出为：
$$
F({x})=\frac{1}{M} \sum_{m=1}^{M} f_{m}({x})
$$
对于投票法的误差，有如下定理：对于$M$个不同的模型$f_1(x),\cdots,f_M(x)$，其平均期望错误为$\bar{\mathcal R}(f)$。基于简单投票机制的集成模型$F(x)$的**期望错误**位于$\frac{1}{M}\bar{\mathcal R}(f)$和$\bar{\mathcal R}(f)$之间。证明如下：

根据定义，集成模型的期望错误为：
$$
\begin{aligned}
\mathcal{R}(F) &=\mathbb{E}_x\left[\left(\frac{1}{M} \sum_{m=1}^{M} f_{m}({x})-h({x})\right)^{2}\right] \\
&=\mathbb{E}_x\left[\left(\frac{1}{M} \sum_{m=1}^{M} \epsilon_{m}({x})\right)^{2}\right] \\
&=\frac{1}{M^{2}} \mathbb{E}_x\left[\sum_{m=1}^{M} \sum_{n=1}^{M} \epsilon_{m}({x}) \epsilon_{n}({x})\right] \\
&=\frac{1}{M^{2}} \sum_{m=1}^{M} \sum_{n=1}^{M} \mathbb{E}_{{x}}[\epsilon_{m}({x}) \epsilon_{n}({x})]
\end{aligned}
$$
其中$\mathbb{E}_{\boldsymbol{x}}[\epsilon_{m}({x}) \epsilon_{n}({x})]$是两个**不同模型错误的相关性**。若每个模型的错误**不相关**，即$\forall m \neq n, \mathbb{E}_{{x}}[\epsilon_{m}({x}) \epsilon_{n}({x})]=0$，此时$\mathcal R(F)$达到**下界**。如果每个模型的错误都是**相同的**，则$\forall m \neq n, \epsilon_{m}({x})=\epsilon_{n}({x})$，此时$\mathcal R(F)$达到**上界**。并且由于$\epsilon_{m}({x}) \geq 0, \forall m$，可以得到：
$$
\bar{\mathcal{R}}(f) \geq \mathcal{R}(F) \geq \frac{1}{M} \bar{\mathcal{R}}(f)
$$
即集成模型的期望错误大于等于所有模型的平均期望错误的$1/M$，小于等于所有模型的平均期望错误。因此模型之间的差异性对于提升模型集成效果是十分重要的。

### 9.3 Boosting

Boosting类集成模型的目标是学习一个**加性模型(additive model)**。：
$$
F({x})=\sum_{m=1}^{M} \alpha_{m} f_{m}({x})
$$
其中$f_m(x)$为弱分类器或基分类器，$\alpha_m$为弱分类器的继承权重，$F(x)$称为强分类器。

Boosting类方法的关键是如何训练每个**弱分类器**$f_m(x)$以及对应的**权重**。为了提高集成的效果，应当**尽量使得每个弱分类器的差异尽可能大**。一种有效的算法是采用迭代的方法来学习每个弱分类器，即按照一定的顺序依次训练每个弱分类器。在学习了第$m$个弱分类器后，**增加其分错样本的权重**，使得第$m+1$个弱分类器**更关注于前面弱分类器分错的样本**。这样增加每个弱分类器的差异，最终提升集成分类器的准确率。这种方法称为**AdaBoost算法**。

<img src="images/image-20200429101848886.png" style="zoom:50%;" />

AdaBoost算法是一种**迭代式的训练算法**，通过改变数据分布来提高弱分类器的差异。在每一轮训练中，增加分错样本的权重，减少分对样本的权重，从而得到一个新的数据分布。

以**二分类**为例，AdaBoost算法的训练过程如下所示。**最初赋予每个样本同样的权重**，在每一轮迭代中，根据当前的样本权重训练一个新的弱分类器，然后根据这个弱分类器的错误率来计算其集成权重，并调整样本权重。

<img src="images/image-20200429154348279.png" style="zoom:50%;" />

### 9.4 Bagging与随机森林

#### 9.4.1 Bagging

Bagging是并行集成学习方法最著名的代表，其能在训练数据的变体上拟合多个模型。训练数据的变体使用自助采样法创建，即每个组件估计器只学习数据集中的一部分，而不是整个数据集。经过多次采样后，初始训练集中约有63.2%的样本出现在采样集中。照这样，我们可采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练一个基学习器，然后将这些基学习器进行结合。在对预测输出进行结合时，**Bagging通常对分类任务采用简单投票法，对回归任务采用简单平均法**。

假定基学习器的计算复杂度为$O(m)$，则Bagging的复杂度大致为$T(O(m)+O(s))$。考虑到采样与投票/平均过程的复杂度$O(s)$很小，而$T$通常是一个不太大的常数，因此，**训练一个Bagging集成与直接使用基学习算法训练一个学习器的复杂度同阶**，这说明Bagging是一个很高效的集成学习算法。另外，与AdaBoost只适用于二分类任务不同，Bagging能不经修改地用于多分类、回归等任务。

自助采样过程还给Bagging带来另一个优点：由于每个基学习器只使用了初始训练集中约63.2%的样本，剩下约36.8%的样本可用于验证集对泛化性能进行**包外估计(out-of-bag estimate)**。

事实上，包外样本还有许多其他用途。例如当基学习器是决策树时，可**使用包外样本来辅助剪枝**，或用于估计决策树中各结点的后验概率以辅助对零训练样本结点的处理；当基学习器是神经网络时，可**使用包外样本来辅助早期停止以减小过拟合风险**。

从偏差-方差分析的角度看，**Bagging主要关注降低方差**，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显。

#### 9.4.2 随机森林

**随机森林(random forest, RF)**是Bagging的一个变体。**RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择**。具体来说，传统决策树在选择划分属性时是在当前结点的属性集合(假设有$d$个属性)中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含$k$个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数$k$控制了**随机性的引入程度**：若令$k=d$，则基决策树的构建与传统决策树相同；若令$k=1$，则是随机选择一个属性用于划分；一般情况下，推荐值为$k=\log_2 d$。

随机森林中的基学习器的**多样性不仅来自样本扰动，还来自属性扰动**。这就使得最终集成的泛化性能可通过个体学习器之间的差异度的增加而进一步提升。下图为单个决策树和随机森林所学习到的决策边界。

<img src="images/image-20200429101757276.png" style="zoom:50%;" />

### 9.5 结合策略

学习器结合可能会从三个方面带来好处：(1) 从**统计**的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器则会减小这一风险；(2) 从**计算**的方面来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入局部极小点的风险；(3) 从**表示**的方面来看，某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大有可能学得更好的近似。学习器的三种常见结合策略如下：

(1) **平均法(averaging)**：对数值型输出(回归)最常见的结合策略，可以分为简单平均和加权平均等策略。

(2) **投票法(voting)**：对分类任务最常见的结合策略。可分为绝对多数投票法(若某标记得票超过半数，则预测为该标记，否则拒绝预测)、相对多数投票法(预测为得票最多的标记，若同时有多个标记获得最高票，则从中随机选择一个)和加权投票法等。

(3) **学习法(learning)**：通过另一个学习器来学习基学习器的结果，**Stacking**是学习法的典型代表。在学习法中，我们把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器。

<img src="images/image-20200429110022093.png" style="zoom:50%;" />

Stacking先从初始训练集训练处初级学习器，然后生成一个新数据集用于训练次级学习器。在新数据集中，初级学习器的输出被当做样例输入特征，而初始样本标记仍被当做样例标记。

### 9.6 GBDT



### 参考资料

[1] 李航. 统计学习方法. 北京: 清华大学出版社, 2019.

[2] 周志华. 机器学习. 北京: 清华大学出版社, 2016.

[3] 邱锡鹏. 神经网络与深度学习. 2019.

[4] Géron A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. O'Reilly Media, 2019.