## 百度题库试题知识点标注项目

### 项目概述

项目由百度提供，对试题进行自动分类，是一个多层级、多类别、多标签的文本分类项目。给定一个试题，需要预测如“高中 历史 近代史”等三层类别信息，尽可能提供准确的知识点备选，同时预测试题的多个知识点标签。数据主要来自于互联网爬取。

所用算法：朴素贝叶斯(只能完成多分类，本身并无法进行多标签分类)、FastText、RNN、TextCNN、GCN、BERT、ERNIE。


### 一. 项目文件

#### 1. data\: 存放项目的原始数据和经过处理的中间数据

stopwords\: 包含常用的停用词表

百度题库\: 项目未经处理的原始数据

baidu_95.csv: 将知识点标签(95个，仅取300频次以上的标签)与试题原始文本合在一起的中间数据文件

df.csv: baidu_95.csv中知识点标签不变，试题原始文本经过处理(无用词去除、切词等)后的中间数据文件

labels_baidu_95.txt: 设计的95个知识点标签的列表

sentiment_analysis.csv: 0/1情感分类数据集

vocab.txt: 词典文件

X_train.npy: 训练语料，shape为(18060, 300)

X_test.npy: 测试语料，shape为(4516, 300)

y_train.npy: 训练类别标签，shape为(18060, 95)

y_test.npy: 测试类别标签，shape为(4516, 95)

#### 2. model\: 存放不同文本分类模型的代码

bayes_classifier.py: 贝叶斯分类器(百度题库高中历史试题三分类)

fasttext_classifier.py: fastText分类器(英文情感分析)

rnn_classifier: 循环神经网络分类器(英文情感分析)

**gcn_classifier: 图卷积神经网络分类器(未完成)**

text_cnn_classifier.py: 卷积神经网络分类器(百度题库多标签分类)

bert_classifier\: BERT文本分类器(百度题库多标签分类)

ernie_classifier.py: ERNIE文本分类器(百度题库多标签分类)

classify.py: 传入模型名称，调用以上七种不同的模型进行文本分类

#### 3. results\：

存放模型对测试数据集的的预测结果及保存的模型

#### 4. utils\：

config.py: 项目配置文件

data_loader.py: 将原始数据处理为适用于模型输入的格式，并产生中间结果，只需执行一次

metrics.py: 分类问题的评价指标

multi_proc_utils.py: 多核并行工具


### 二. 执行步骤

(1) 将百度题库原始数据拷贝到data\目录下。

(2) 运行data_processor文件，生成baidu_{label_num}.csv文件。

(3) 运行data_loader文件，生成npy矩阵(主要用于TextCNN)。

(4) 在classify.py文件中更改所用分类器的名字以及运行模式，运行该文件以完成不同的文本分类任务。其中BERT若想获取微平均和宏平均F1值的话，需要执行evaluate_test.py文件，其EVAL和PREDICT模式均只产生结果文件。


### 三. 实验结果

#### 1. 高中历史试题多分类实验结果(朴素贝叶斯)

##### (1) CountVectorizer提取特征的多项式朴素贝叶斯算法实验结果: 

|           |precision |recall    |f1-score  |support   |
|-----------|----------|----------|----------|----------|
|0          |0.82      |0.91      |0.86      |265       |
|1          |0.64      |0.71      |0.68      |397       |
|2          |0.75      |0.67      |0.71      |581       |
|avg / total|0.73      |0.73      |0.73      |1243      |

##### (2) TfidfVectorizer提取特征的多项式朴素贝叶斯算法实验结果: 

|           |precision |recall    |f1-score  |support   |
|-----------|----------|----------|----------|----------|
|0          |0.98      |0.71      |0.82      |251       |
|1          |0.82      |0.45      |0.58      |424       |
|2          |0.64      |0.93      |0.76      |568       |
|avg / total|0.77      |0.72      |0.71      |1243      |

#### 2. 情感分类实验结果(FastText、RNN)

##### (1) FastText情感分类实验结果

|epoch     |1      |2      |3      |4      |5      |
|----------|-------|-------|-------|-------|-------|
|train loss|0.0878 |0.0066 |0.0034 |0.0025 |0.0023 |
|train acc |0.9662 |0.9980 |0.9993 |0.9995 |0.9995 |
|test loss |0.0182 |0.0184 |0.0182 |0.0183 |0.0185 |
|test acc  |0.9954 |0.9945 |0.9950 |0.9951 |0.9949 |

##### (2) RNN情感分类实验结果

|epoch     |1      |2      |3      |4      |5      |
|----------|-------|-------|-------|-------|-------|
|train loss|0.0813 |0.0076 |0.0049 |0.0020 |0.0044 |
|train acc |0.9659 |0.9977 |0.9989 |0.9992 |0.9985 |
|test loss |0.0186 |0.0175 |0.0251 |0.0382 |0.0355 |
|test acc  |0.9944 |0.9951 |0.9923 |0.9919 |0.9888 |

#### 3. 百度题库多标签分类实验结果(TextCNN、BERT、ERNIE)

##### (1) TextCNN多标签分类实验结果

|epoch     |1      |2      |3      |4      |5      |
|----------|-------|-------|-------|-------|-------|
|test loss |0.0383 |0.0329 |0.0341 |0.0393 |0.0429 |
|micro f1  |0.8887 |0.9087 |0.9106 |0.9073 |0.9108 |
|macro f1  |0.7165 |0.7743 |0.7873 |0.7965 |0.8060 |

##### (2) BERT多标签分类实验结果

|epoch     |5      |
|----------|-------|
|micro f1  |0.9198 |
|macro f1  |0.7703 |

##### (3) ERNIE多标签分类实验结果

|epoch     |5      |
|----------|-------|
|micro f1  |0.9273 |
|macro f1  |0.8316 |


### 四. 项目总结

文本分类是自然语言处理领域的基础任务之一，属于“序列到类别”任务范式，通常使用分类准确率、精准率和召回率等指标进行评价。

本项目使用多种方法进行文本分类(多类别/多标签)，从整体效果上来看，预训练模型(如BERT/ERNIE)往往能够取得更好的效果。由于时间原因，没有进行大量的实验并进行实验结果的汇总，在此仅给出一个简单的分析。

分类问题是机器学习领域最基本的问题之一，而文本分类则是自然语言处理领域最基本的问题之一。使用神经网络进行文本分类，往往依靠输出层的softmax函数进行多类别分类，或者依靠sigmoid函数进行多标签分类，这是分类任务本身。而对于分类任务来说，更重要的是输出层之前的特征提取，而特征提取的好坏往往对实验结果有着巨大影响。例如，TextCNN使用卷积核的短距离依赖特性进行特征提取，RNN利用文本的长距离序列特性进行特征提取，二者虽然均取得了不错的效果，但由于所产生的词嵌入无法解决一词多义问题，因此还有很大的提升空间。BERT和ERNIE这类预训练语言模型产生的词的表示是上下文相关的，因此提取出来的特征效果更优。
