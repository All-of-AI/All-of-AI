## 百度问答摘要与推理项目

### 项目概述

本次比赛主题为汽车大师问答摘要与推理。要求使用汽车大师提供的11万条技师与用户的多轮对话与诊断建议报告 数据建立模型，模型需基于对话文本、用户问题、车型与车系，输出包含摘要与推断的报告文本，综合考验模型的归纳总结与推断能力。

该项目采用如下四种实现方式：

(1) seq2seq+attention实现：作为本项目的baseline；

(2) Pointer-Generator Network实现：针对seq2seq中的OOV和repetition问题进行优化；

(3) TextRank实现：抽提式文本摘要能够获得更高的ROUGE值；

(4) ERNIE实现：使用预训练语言模型对句子进行文本分类以产生摘要。

每种实现方式都对参数进行了试探性的调整，并记录了实验结果。


### 一. 项目文件

#### 1. data\：

checkpoints\：模型检查点保存目录

stopwords\：含多个版本的停用词表

TrueType\：含字体文件

wv\：含预先训练的词向量(供TextRank使用)

AutoMaster_TestSet.csv：训练数据原始文件

AutoMaster_TrainSet.csv：测试数据原始文件

vocab.txt：字典文本文件

inverse_vocab.txt：反向字典文本文件

user_dict.txt：用户词典，用于jieba切词

train_seg_data.csv：Q9368,路虎,第三代发现,<START> 路虎 发现 3 车子 停好 后 有汽 喷出 ， 久 不久 又 喷出来 一点 那 样子 ， 是 什么 坏 了 <END>,<START> 您好 ， 从 哪个 地方 喷气 。 可以 详细描述 一下 。 最好 能 拍照 上传 ， 谢谢 <END>,<START> 抱歉 ， 由于 您 长时间 没有 回复 ， 案例 已经 关闭 ， 您 可以 关注 我 ， 将 问题 一对一 发送 过来 ， 我 详细 给 您 解答 。 <END>

test_seg_data.csv：Q1,大众(进口),高尔夫(进口),<START> 我 的 帕萨特 烧 机油 怎么办 怎么办 。 <END>,<START> 你好 ， 请问 你 的 车 跑 了 多少 公里 了 ， 如果 在 保修期 内 ， 可以 到 当地 的 4 店 里面 进行 检查 维修 。 如果 已经 超出 了 保修期 建议 你 到 当地 的 大型 维修 店 进行 检查 ， 烧 机油 一般 是 发动机 活塞环 间隙 过大 和 气门 油封 老化 引起 的 。 如果 每 750 0 公里 烧一升 机油 的话 ， 可以 在 后备箱 备 一些 机油 ， 以便 机油 报警 时有 机油 及时 补充 ， 如果 超过 两升 或者 两升 以上 ， 建议 你 进行 发动机 检查 维修 。 你好 <END>

train_X_seg.csv：<START> 方向机 重 ， 助力 泵 ， 方向机 都 换 了 还是 一样 <END> <START> 新 的 都 换 了 助力 泵 ， 方向机 换 了 方向机 带 的 有 有 助力 就是 重 ， 这车 要 匹配 不 需要 你 这 是 更换 的 部件 有 问题 跑 快 了 还好 点 ， 就 倒车 重 的 很 。 是 非常 重是 的 ， 累人 我 觉得 也 是 ， 可是 车主 是 以前 没 这么 重 ， 选 助理 泵 换 了 不行 ， 又 把 放 向 机换 了 ， 现在 还 这样 就 不 知道 咋 和 车主 解释 。 <END>

train_Y_seg.csv：<START> 行驶 没有 顿挫 的 感觉 ， 原地 换挡 有 闯动 ， 刹车 踩 重 没有 ， 这 是 力 的 限制 的 作用 ， 应该 没有 问题 <END>

test_X_seg.csv：<START> 我 的 帕萨特 烧 机油 怎么办 怎么办 。 <END> <START> 你好 ， 请问 你 的 车 跑 了 多少 公里 了 ， 如果 在 保修期 内 ， 可以 到 当地 的 4 店 里面 进行 检查 维修 。 如果 已经 超出 了 保修期 建议 你 到 当地 的 大型 维修 店 进行 检查 ， 烧 机油 一般 是 发动机 活塞环 间隙 过大 和 气门 油封 老化 引起 的 。 如果 每 750 0 公里 烧一升 机油 的话 ， 可以 在 后备箱 备 一些 机油 ， 以便 机油 报警 时有 机油 及时 补充 ， 如果 超过 两升 或者 两升 以上 ， 建议 你 进行 发动机 检查 维修 。 你好 <END>

train_X.npy：训练数据X部分(问题和对话)转为numpy数组后的文件

train_Y.npy：训练数据Y部分(摘要)转为numpy数组后的文件

test_X.npy：测试数据X部分(问题和对话)转为numpy数组后的文件

#### 2. utils\：

config.py：存放项目中常用路径常量

gpu_utils.py：含GPU配置函数

load_data.py：将原始数据进行处理，转变为适合神经网络输入的格式

multi_proc_utils.py：含多核处理函数

params_utils.py：包含seq2seq与PGN网络所用到的超参数

#### 3. seq2seq_model\：

batcher.py：为seq2seq网络生成tf.data.Dataset格式的训练数据

layers.py：包含seq2seq+attention网络中不同层的前向传播定义

model.py：包含seq2seq+attention整体模型的定义

train.py：模型训练入口

train_helper.py：模型训练所需要的函数

test.py：模型测试入口

test_helper.py：模型测试所需要的函数

#### 4. pgn_model\：

batcher.py：生成符合PGN网络输入格式的数据

layers.py：包含PGN网络中不同层的前向传播定义

loss.py：包含损失函数的定义

model.py：包含PGN整体模型的定义

train.py：模型训练入口

train_helper.py：模型训练所需要的函数

test.py：模型测试入口

test_helper.py：模型测试所需要的函数

#### 5. textrank_model\：

model.py：包含TextRank模型的数据处理、模型构建以及结果生成

#### 6. ernie_model\：

model.py：使用PaddleHub构建ERNIE模型，并完成摘要的生成。具体地，生成对话对，然后使用文本分类方法决定哪个句子该出现在摘要中

post_process.py：将ERNIE生成的摘要结果进行进一步处理。

#### 7. results\：

存放模型对测试数据集的的预测结果


### 二. 执行步骤

(1) 执行utils\load_data.py，加载数据。

(2) 对于seq2seq+attention的baseline，运行seq2seq_model\目录下的train.py和test.py分别进行训练和测试。

(3) 对于PGN模型，运行pgn_model\目录下的train.py和test.py分别进行训练和测试。

(4) 对于TextRank模型，运行textrank_model\目录下的model.py，一键进行训练和测试。

(5) 对于ERNIE模型，运行ernie_model\目录下的model.py，一键进行训练和测试；再运行post_process进行结果的处理，删除无用词汇。


### 三. 实验结果

#### 1. seq2seq+attention实验结果

|epoch   |1      |2      |3      |4      |5      |6      |7      |8      |9      |10     |
|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|
|ROUGE_L |28.8454|29.5779|29.1899|29.7182|29.7477|29.4956|29.2062|29.4269|29.2064|29.0873|

#### 2. PGN实验结果

|epoch   |1      |2      |3      |4      |5      |6      |7      |8      |9      |10     |
|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|
|ROUGE_L |28.9716|30.4729|30.4926|30.3222|30.1585|29.8060|29.6210|29.5847|29.2893|29.5021|

#### 3. TextRank实验结果

|config       |ROUGE_L|
|-------------|-------|
|top 2 sents  |37.1639|
|top 3 sents  |37.8341|

#### 4. ERNIE实验结果

|epoch   |1      |
|--------|-------|
|ROUGE_L |36.6419|

### 四. 项目总结

文本摘要是将长文本使用简短的文本进行表达的技术，属于“序列到序列”这一范式的自然语言处理任务，通常使用ROUGE对结果进行评价。

本项目首先使用seq2seq+attention实现生成式文本摘要作为baseline，然后复现PGN模型(依然是生成式文本摘要模型，只不过对OOV和repetition做了改进)。

随后，使用TextRank方法进行抽提式摘要，经几步优化后ROUGE_L进一步提高。

最后，尝试使用预训练语言模型ERNIE以文本分类的方式进行摘要的生成。

在实现项目的过程中走了许多弯路，即在数据预处理上尝试了不同的方法(中文不分词而是按汉字进行划分等)，但都未获得明显的效果提升。

近两年也出现了将生成式文本摘要和抽提式文本摘要相结合的方式，这也许是未来有潜力的研究方向之一。
