## 知识图谱2 知识表示学习

基于网络形式的知识表示面临如下两个方面的挑战性难题：

(1) **计算效率问题**：基于网络的知识表示形式中，每个实体均用不同的节点表示。当利用知识库计算实体间的语义或推理关系时，往往需要人们设计专门的图算法来实现，存在可移植性差的问题。更重要的是，基于图的算法计算复杂度高、可扩展性差，当知识库到达一定规模时，就很难较好地满足实时计算的需求。

(2) **数据稀疏问题**：与其他类型的大规模数据类似，大规模知识库也遵守长尾分布，在长尾部分的实体和关系上，面临严重的数据稀疏问题。例如，对于长尾分布的罕见实体，由于只有极少的知识或路径涉及它们，对这些实体的语义或推理关系的计算往往准确率极低。

近年来，以深度学习为代表的表示学习技术异军突起，在语音识别、图像分析和自然语言处理领域获得广泛关注。表示学习旨在将研究对象的语义信息表示为稠密低维实值向量。在该低维向量空间中，**两个对象距离越近则说明其语义相似度越高**。

**知识表示学习是面向知识库中的实体和关系进行的表示学习**。该方向最近取得了重要进展，可以在低维空间中高效计算实体和关系的语义联系，有效解决数据稀疏问题，使知识获取、融合和推理的性能得到显著提升。

以知识库中的实体$e$和关系$r$为例，将表示学习得到的向量表示为$\boldsymbol l_e$和$\boldsymbol l_r$。在该向量空间中，我们可以通过欧氏距离或余弦距离等方式，计算任意两个对象之间的语义相似度。

### 2.1 翻译模型

表示学习在自然语言处理领域受到广泛关注起源于Mikolov等人于2013年提出的word2vec词表示学习模型和工具包。利用该模型，Mikolov等人发现词向量空间存在有趣的平移不变现象，例如：
$$
\boldsymbol C(king)-\boldsymbol C(queen) \approx \boldsymbol C(man) - \boldsymbol C(woman)
$$
受该现象的启发，Bordes等人提出了**TransE模型**，将知识库中的关系看作实体间的某种平移向量。对于每个三元组$(h, r, t)$，TransE用关系$r$，作为头实体向量$\boldsymbol l_h$和尾实体向量$\boldsymbol l_t$之间的**平移**。我们也可以将$\boldsymbol l_r$看作从$\boldsymbol l_h$到$\boldsymbol l_t$的翻译，因此TransE也被称为翻译模型。

对于每个三元组$(h, r, t)$，TransE希望$\boldsymbol l_h + \boldsymbol l_r \approx \boldsymbol l_t$。因此定义如下损失函数：
$$

$$
